"""
Application Streamlit pour la d√©tection de pi√®ces d'entrep√¥t
Version corrig√©e - Utilisation de YOLOv5 via torch.hub
"""

import streamlit as st
import cv2
import numpy as np
import torch
import tempfile
import os
from PIL import Image
import pandas as pd
from datetime import datetime
import requests
from pathlib import Path

# Configuration de la page
st.set_page_config(
    page_title="D√©tection Pi√®ces Entrep√¥t",
    page_icon="üè≠",
    layout="wide"
)

# Titre
st.title("üè≠ Syst√®me de D√©tection de Pi√®ces d'Entrep√¥t")
st.markdown("---")

# Sidebar pour la configuration
with st.sidebar:
    st.header("‚öôÔ∏è Configuration")
    
    # Choix de la source
    source = st.radio(
        "Source d'image:",
        ["üì∑ Cam√©ra", "üìÅ Upload image", "üé• Vid√©o"]
    )
    
    # Seuil de confiance
    confidence = st.slider(
        "Seuil de confiance",
        min_value=0.0,
        max_value=1.0,
        value=0.5,
        step=0.05
    )
    
    # Choix du mod√®le
    model_choice = st.selectbox(
        "Mod√®le",
        ["yolov5s (rapide)", "yolov5m (pr√©cis)", "yolov5n (tr√®s rapide)"]
    )
    
    model_map = {
        "yolov5s (rapide)": "yolov5s",
        "yolov5m (pr√©cis)": "yolov5m",
        "yolov5n (tr√®s rapide)": "yolov5n"
    }
    
    st.markdown("---")
    st.header("üìä Base de donn√©es")
    
    # Informations sur les pi√®ces
    piece_info = {
        "boulon": {"prix": "0.50‚Ç¨", "stock": 150, "emplacement": "A-12"},
        "vis": {"prix": "0.30‚Ç¨", "stock": 300, "emplacement": "B-03"},
        "ecrou": {"prix": "0.20‚Ç¨", "stock": 200, "emplacement": "C-07"},
        "rondelle": {"prix": "0.15‚Ç¨", "stock": 500, "emplacement": "A-05"},
        "clou": {"prix": "0.10‚Ç¨", "stock": 1000, "emplacement": "D-01"}
    }
    
    df_info = pd.DataFrame(piece_info).T
    st.dataframe(df_info)

# Fonction pour charger le mod√®le YOLOv5
@st.cache_resource
def load_model(model_name="yolov5s"):
    """Charger le mod√®le YOLOv5 via torch.hub"""
    try:
        with st.spinner(f"Chargement du mod√®le {model_name}..."):
            # Charger depuis torch hub
            model = torch.hub.load('ultralytics/yolov5', model_name, pretrained=True)
            return model
    except Exception as e:
        st.error(f"Erreur chargement mod√®le: {e}")
        return None

# Fonction de d√©tection
def detect_objects(model, image, conf_threshold):
    """D√©tecter les objets dans l'image"""
    if model is None:
        return None
    
    # Conversion de l'image si n√©cessaire
    if isinstance(image, np.ndarray):
        # Convertir BGR en RGB si n√©cessaire
        if len(image.shape) == 3 and image.shape[2] == 3:
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        else:
            image_rgb = image
    else:
        image_rgb = image
    
    # Faire la d√©tection
    results = model(image_rgb)
    
    # Convertir en DataFrame
    detections = results.pandas().xyxy[0]
    detections = detections[detections['confidence'] >= conf_threshold]
    
    return detections, results

# Fonction pour dessiner les bo√Ætes
def draw_boxes(image, results):
    """Dessiner les bo√Ætes de d√©tection sur l'image"""
    if results is None:
        return image
    
    # R√©cup√©rer l'image avec les bo√Ætes
    img_with_boxes = results.render()[0]
    return img_with_boxes

# Interface principale
col1, col2 = st.columns(2)

with col1:
    st.header("üì∑ Image Source")
    
    image = None
    video_path = None
    
    if source == "üì∑ Cam√©ra":
        # Capture cam√©ra
        img_file = st.camera_input("Prendre une photo")
        if img_file is not None:
            bytes_data = img_file.getvalue()
            image = cv2.imdecode(np.frombuffer(bytes_data, np.uint8), cv2.IMREAD_COLOR)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            st.image(image, caption="Image captur√©e", use_column_width=True)
            
    elif source == "üìÅ Upload image":
        # Upload d'image
        img_file = st.file_uploader("Choisir une image", type=['jpg', 'jpeg', 'png'])
        if img_file is not None:
            image = Image.open(img_file)
            image = np.array(image)
            st.image(image, caption="Image upload√©e", use_column_width=True)
            
    else:  # Vid√©o
        video_file = st.file_uploader("Choisir une vid√©o", type=['mp4', 'avi', 'mov'])
        if video_file is not None:
            # Sauvegarder temporairement la vid√©o
            tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
            tfile.write(video_file.read())
            video_path = tfile.name
            st.video(video_path)

with col2:
    st.header("üéØ R√©sultats D√©tection")
    
    if st.button("üöÄ Lancer la d√©tection", type="primary"):
        if image is not None or video_path is not None:
            # Charger le mod√®le
            model_name = model_map[model_choice]
            model = load_model(model_name)
            
            if model is not None:
                if image is not None:
                    # D√©tection sur image
                    with st.spinner("Analyse de l'image en cours..."):
                        detections, results = detect_objects(model, image, confidence)
                        
                        if detections is not None and len(detections) > 0:
                            st.success(f"‚úÖ {len(detections)} pi√®ce(s) d√©tect√©e(s)!")
                            
                            # Afficher l'image avec bo√Ætes
                            img_with_boxes = draw_boxes(image, results)
                            st.image(img_with_boxes, caption="R√©sultat d√©tection", use_column_width=True)
                            
                            # Afficher le tableau des d√©tections
                            st.subheader("üìã D√©tails des d√©tections")
                            
                            # Ajouter les informations des pi√®ces
                            display_df = detections[['name', 'confidence', 'xmin', 'ymin', 'xmax', 'ymax']].copy()
                            display_df['confiance (%)'] = (display_df['confidence'] * 100).round(1)
                            
                            # Ajouter les infos de la base
                            display_df['prix'] = display_df['name'].map(lambda x: piece_info.get(x, {}).get('prix', 'N/A'))
                            display_df['emplacement'] = display_df['name'].map(lambda x: piece_info.get(x, {}).get('emplacement', 'N/A'))
                            
                            st.dataframe(display_df[['name', 'confiance (%)', 'prix', 'emplacement']])
                            
                            # Log de la d√©tection
                            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                            st.caption(f"üïê D√©tection effectu√©e le: {timestamp}")
                            
                        else:
                            st.warning("‚ö†Ô∏è Aucune pi√®ce d√©tect√©e. Essayez d'ajuster le seuil de confiance.")
                            
                elif video_path is not None:
                    st.info("üé• D√©tection sur vid√©o - Fonctionnalit√© √† venir...")
            else:
                st.error("‚ùå Impossible de charger le mod√®le")
        else:
            st.warning("‚ö†Ô∏è Veuillez d'abord capturer ou uploader une image")

# Pied de page
st.markdown("---")
st.markdown("""
<div style='text-align: center'>
    <p>üè≠ <strong>Syst√®me de D√©tection de Pi√®ces d'Entrep√¥t</strong> - YOLOv5 + Streamlit</p>
    <p>üì∏ Prenez une photo, uploadez une image ou une vid√©o pour d√©tecter automatiquement les pi√®ces</p>
    <p>üîó <a href='https://github.com/aymaneaamr/detection-pieces-entrepot' target='_blank'>GitHub Repository</a></p>
</div>
""", unsafe_allow_html=True)

# Instructions d'utilisation
with st.expander("üìñ Comment utiliser cette application"):
    st.markdown("""
    ### Guide d'utilisation
    
    1. **Choisissez une source d'image** dans la barre lat√©rale
    2. **Prenez une photo** avec votre cam√©ra ou **uploader une image**
    3. **Ajustez le seuil de confiance** si n√©cessaire
    4. **Cliquez sur "Lancer la d√©tection"**
    5. **Visualisez les r√©sultats** avec les bo√Ætes de d√©tection
    
    ### Mod√®les disponibles
    - **yolov5n** : Tr√®s rapide, moins pr√©cis (nano)
    - **yolov5s** : Rapide, bon √©quilibre (small) - recommand√©
    - **yolov5m** : Plus lent, plus pr√©cis (medium)
    
    ### Pi√®ces d√©tectables
    - Boulons, vis, √©crous, rondelles, clous
    - Les informations (prix, stock, emplacement) sont affich√©es automatiquement
    """)
